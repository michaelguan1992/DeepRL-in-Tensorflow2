{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import gym\n",
    "from gym.spaces import Box, Discrete\n",
    "import time\n",
    "\n",
    "import scipy.signal\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "functions in core.py\n",
    "\"\"\"\n",
    "EPS = 1e-8\n",
    "\n",
    "\n",
    "def combined_shape(length, shape=None):\n",
    "    if shape is None:\n",
    "        return (length,)\n",
    "    return (length, shape) if np.isscalar(shape) else (length, *shape)\n",
    "\n",
    "\n",
    "def discount_cumsum(x, discount):\n",
    "    \"\"\"\n",
    "    magic from rllab for computing discounted cumulative sums of vectors.\n",
    "    input:\n",
    "      vector x,\n",
    "      [x0,\n",
    "       x1,\n",
    "       x2]\n",
    "    output:\n",
    "      [x0 + discount * x1 + discount^2 * x2,\n",
    "       x1 + discount * x2,\n",
    "       x2]\n",
    "    \"\"\"\n",
    "    return scipy.signal.lfilter([1], [1, float(-discount)], x[::-1], axis=0)[::-1]\n",
    "\n",
    "\n",
    "def gaussian_likelihood(x, mu, log_std):\n",
    "    pre_sum = -0.5 * (((x - mu) / (tf.exp(log_std) + EPS))**2 + 2 * log_std + np.log(2 * np.pi))\n",
    "    return tf.reduce_sum(pre_sum, axis=1)\n",
    "\n",
    "\n",
    "def make_mlp_model(input_shape, sizes, activation='tanh', output_activation=None):\n",
    "    \"\"\" Build a feedforward neural network. \"\"\"\n",
    "    mlp = tf.keras.Sequential()\n",
    "    mlp.add(tf.keras.layers.Dense(sizes[0], activation=activation, input_shape=(input_shape,)))\n",
    "    if len(sizes) > 2:\n",
    "        for size in sizes[1:-1]:\n",
    "            mlp.add(tf.keras.layers.Dense(size, activation=activation))\n",
    "\n",
    "    mlp.add(tf.keras.layers.Dense(sizes[-1], activation=output_activation))\n",
    "    return mlp\n",
    "\n",
    "def statistics_scalar(x):\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    return np.mean(x), np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Actor-Critics\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ActorCritic:\n",
    "    def __init__(self, obs_dim, hidden_sizes=(64, 64), activation='tanh', output_activation=None, action_space=None, pi_lr=3e-4, vf_lr=1e-3, train_v_iters=80):\n",
    "        if isinstance(action_space, Box):\n",
    "            act_dim = len(action_space.sample())\n",
    "            self.pi_mlp = make_mlp_model(obs_dim, list(hidden_sizes) + [act_dim], activation, output_activation)\n",
    "            self.policy = self._mlp_gaussian_policy\n",
    "            self.log_std = tf.Variable(name='log_std', initial_value=-0.5 * np.ones(act_dim, dtype=np.float32))\n",
    "\n",
    "        elif isinstance(action_space, Discrete):\n",
    "            act_dim = action_space.n\n",
    "            self.pi_mlp = make_mlp_model(obs_dim, list(hidden_sizes) + [act_dim], activation, None)\n",
    "            self.policy = self._mlp_categorical_policy\n",
    "            self.action_space = action_space\n",
    "        self.v_mlp = make_mlp_model(obs_dim, list(hidden_sizes) + [1], activation, None)\n",
    "        # optimizers\n",
    "        self.pi_optimizer = tf.optimizers.Adam(learning_rate=pi_lr)\n",
    "        self.vf_optimizer = tf.optimizers.Adam(learning_rate=vf_lr)\n",
    "        self.train_v_iters = train_v_iters\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, observation, action):\n",
    "        pi, logp_pi = self.policy(observation, action)\n",
    "        v = tf.squeeze(self.v_mlp(observation), axis=1)\n",
    "        return pi, logp_pi, v\n",
    "\n",
    "    def _mlp_categorical_policy(self, observation, action):\n",
    "        act_dim = self.action_space.n\n",
    "        logits = self.pi_mlp(observation)\n",
    "        logp_all = tf.nn.log_softmax(logits)\n",
    "        pi = tfd.Categorical(logits).sample()  # pi is the next action\n",
    "        if action is not None:\n",
    "            action = tf.cast(action, tf.int32)\n",
    "            logp = tf.reduce_sum(tf.one_hot(action, act_dim) * logp_all, axis=1)\n",
    "        else:\n",
    "            logp = tf.reduce_sum(tf.one_hot(pi, act_dim) * logp_all, axis=1)\n",
    "        return pi, logp\n",
    "\n",
    "    def _mlp_gaussian_policy(self, observation, action):\n",
    "        mu = self.pi_mlp(observation)\n",
    "        std = tf.exp(self.log_std)\n",
    "        pi = mu + tf.random.normal(tf.shape(mu)) * std  # pi is the next action\n",
    "        if action is not None:\n",
    "            logp = gaussian_likelihood(action, mu, self.log_std)\n",
    "        else:\n",
    "            logp = gaussian_likelihood(pi, mu, self.log_std)\n",
    "        return pi, logp\n",
    "\n",
    "    def update(self, buf):\n",
    "        obs_buf, act_buf, adv_buf, ret_buf, logp_buf = buf.get()\n",
    "\n",
    "        with tf.GradientTape() as pi_tape, tf.GradientTape() as vf_tape:\n",
    "            pi, logp, v = self.__call__(obs_buf, act_buf)\n",
    "\n",
    "            pi_loss = -tf.reduce_mean(logp * adv_buf)\n",
    "            v_loss = tf.reduce_mean((ret_buf - v) ** 2)\n",
    "\n",
    "        if hasattr(self, 'log_std'):\n",
    "            all_trainable_variables = [self.log_std, *self.pi_mlp.trainable_variables]\n",
    "            pi_grads = pi_tape.gradient(pi_loss, all_trainable_variables)\n",
    "            self.pi_optimizer.apply_gradients(zip(pi_grads, all_trainable_variables))\n",
    "        else:\n",
    "            pi_grads = pi_tape.gradient(pi_loss, self.pi_mlp.trainable_variables)\n",
    "            self.pi_optimizer.apply_gradients(zip(pi_grads, self.pi_mlp.trainable_variables))\n",
    "\n",
    "        vf_grads = vf_tape.gradient(v_loss, self.v_mlp.trainable_variables)\n",
    "        for _ in range(self.train_v_iters):\n",
    "            self.vf_optimizer.apply_gradients(zip(vf_grads, self.v_mlp.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VPGBuffer:\n",
    "    \"\"\"\n",
    "    A buffer for storing trajectories experienced by a VPG agent interacting\n",
    "    with the environment, and using Generalized Advantage Estimation (GAE-Lambda)\n",
    "    for calculating the advantages of state-action pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, size, gamma=0.99, lam=0.95):\n",
    "        self.obs_buf = np.zeros(combined_shape(size, obs_dim), dtype=np.float32)\n",
    "        self.act_buf = np.zeros(combined_shape(size, act_dim), dtype=np.float32)\n",
    "        self.adv_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.rew_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ret_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.val_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.logp_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.gamma, self.lam = gamma, lam\n",
    "        self.ptr, self.path_start_idx, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, val, logp):\n",
    "        \"\"\"\n",
    "        Append one timestep of agent-environment interaction to the buffer.\n",
    "        \"\"\"\n",
    "        assert self.ptr < self.max_size     # buffer has to have room so you can store\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.act_buf[self.ptr] = act\n",
    "        self.rew_buf[self.ptr] = rew\n",
    "        self.val_buf[self.ptr] = val\n",
    "        self.logp_buf[self.ptr] = logp\n",
    "        self.ptr += 1\n",
    "\n",
    "    def finish_path(self, last_val=0):\n",
    "        \"\"\"\n",
    "        Call this at the end of a trajectory, or when one gets cut off\n",
    "        by an epoch ending. This looks back in the buffer to where the\n",
    "        trajectory started, and uses rewards and value estimates from\n",
    "        the whole trajectory to compute advantage estimates with GAE-Lambda,\n",
    "        as well as compute the rewards-to-go for each state, to use as\n",
    "        the targets for the value function.\n",
    "        The \"last_val\" argument should be 0 if the trajectory ended\n",
    "        because the agent reached a terminal state (died), and otherwise\n",
    "        should be V(s_T), the value function estimated for the last state.\n",
    "        This allows us to bootstrap the reward-to-go calculation to account\n",
    "        for timesteps beyond the arbitrary episode horizon (or epoch cutoff).\n",
    "        \"\"\"\n",
    "\n",
    "        path_slice = slice(self.path_start_idx, self.ptr)\n",
    "        rews = np.append(self.rew_buf[path_slice], last_val)\n",
    "        vals = np.append(self.val_buf[path_slice], last_val)\n",
    "        \n",
    "        # the next two lines implement GAE-Lambda advantage calculation\n",
    "        deltas = rews[:-1] + self.gamma * vals[1:] - vals[:-1]\n",
    "        self.adv_buf[path_slice] = discount_cumsum(deltas, self.gamma * self.lam)\n",
    "        \n",
    "        # the next line computes rewards-to-go, to be targets for the value function\n",
    "        self.ret_buf[path_slice] = discount_cumsum(rews, self.gamma)[:-1]\n",
    "        \n",
    "        self.path_start_idx = self.ptr\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"\n",
    "        Call this at the end of an epoch to get all of the data from\n",
    "        the buffer, with advantages appropriately normalized (shifted to have\n",
    "        mean zero and std one). Also, resets some pointers in the buffer.\n",
    "        \"\"\"\n",
    "        assert self.ptr == self.max_size    # buffer has to be full before you can get\n",
    "        self.ptr, self.path_start_idx = 0, 0\n",
    "        # the next two lines implement the advantage normalization trick\n",
    "        adv_mean, adv_std = statistics_scalar(self.adv_buf)\n",
    "        self.adv_buf = (self.adv_buf - adv_mean) / adv_std\n",
    "        return self.obs_buf, self.act_buf, self.adv_buf, self.ret_buf, self.logp_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Vanilla Policy Gradient\n",
    "(with GAE-Lambda for advantage estimation)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def vpg(env, ac_kwargs=None, seed=0, steps_per_epoch=4000, epochs=50, gamma=0.99, lam=0.97, max_ep_len=1000, save_freq=10):\n",
    "\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # Create actor-critic agent \n",
    "    ac_kwargs['action_space'] = env.action_space\n",
    "    ac_kwargs['obs_dim'] = env.observation_space.shape[0]\n",
    "\n",
    "    actor_critic = ActorCritic(**ac_kwargs)\n",
    "\n",
    "\n",
    "    # Experience buffer\n",
    "    obs_dim = env.observation_space.shape\n",
    "    act_dim = env.action_space.shape\n",
    "    buf = VPGBuffer(obs_dim, act_dim, steps_per_epoch, gamma, lam)\n",
    "\n",
    "    \"\"\"\n",
    "    Main loop: collect experience in env and update/log each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    # o for observation, r for reward, d for done\n",
    "    o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "\n",
    "    all_ep_ret = []\n",
    "    summary_ep_ret = []\n",
    "    totalEnvInteracts = []\n",
    "    for epoch in range(epochs):\n",
    "        for t in range(steps_per_epoch):\n",
    "            a, logp_t, v_t = actor_critic(o.reshape(1, -1), None)\n",
    "\n",
    "            # save and log\n",
    "            a = a.numpy()[0]\n",
    "            buf.store(o, a, r, v_t, logp_t)\n",
    "\n",
    "            o, r, d, _ = env.step(a)\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "\n",
    "            terminal = d or (ep_len == max_ep_len)\n",
    "            if terminal or (t == steps_per_epoch - 1):\n",
    "                if not(terminal):\n",
    "                    print('Warning: trajectory cut off by epoch at %d steps.' % ep_len)\n",
    "                # if trajectory didn't reach terminal state, bootstrap value target\n",
    "                last_val = r if d else v_t\n",
    "                buf.finish_path(last_val)\n",
    "\n",
    "                if terminal:\n",
    "                    all_ep_ret.append(ep_ret)\n",
    "                # reset environment\n",
    "                o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "\n",
    "        # Perform VPG update!\n",
    "        actor_critic.update(buf)\n",
    "        mean, std = statistics_scalar(all_ep_ret)\n",
    "        all_ep_ret = []\n",
    "\n",
    "        print(f'epoch {epoch}: mean {mean}, std {std}')\n",
    "        summary_ep_ret.append(mean)\n",
    "        totalEnvInteracts.append((epoch + 1) * steps_per_epoch)\n",
    "\n",
    "\n",
    "    plt.plot(totalEnvInteracts, summary_ep_ret)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 29 steps.\n",
      "epoch 0: mean 22.435028076171875, std 12.585864067077637\n",
      "Warning: trajectory cut off by epoch at 9 steps.\n",
      "epoch 1: mean 25.259492874145508, std 14.363359451293945\n",
      "Warning: trajectory cut off by epoch at 1 steps.\n",
      "epoch 2: mean 25.471338272094727, std 14.30983829498291\n",
      "Warning: trajectory cut off by epoch at 4 steps.\n",
      "epoch 3: mean 25.452228546142578, std 15.446001052856445\n",
      "Warning: trajectory cut off by epoch at 7 steps.\n",
      "epoch 4: mean 27.72916603088379, std 15.816314697265625\n",
      "Warning: trajectory cut off by epoch at 21 steps.\n",
      "epoch 5: mean 27.25342559814453, std 15.443140029907227\n",
      "Warning: trajectory cut off by epoch at 12 steps.\n",
      "epoch 6: mean 27.888111114501953, std 16.95865249633789\n",
      "Warning: trajectory cut off by epoch at 25 steps.\n",
      "epoch 7: mean 28.80434799194336, std 16.78243637084961\n",
      "Warning: trajectory cut off by epoch at 8 steps.\n",
      "epoch 8: mean 31.43307113647461, std 18.406858444213867\n",
      "Warning: trajectory cut off by epoch at 9 steps.\n",
      "epoch 9: mean 33.25833511352539, std 21.047761917114258\n",
      "Warning: trajectory cut off by epoch at 8 steps.\n",
      "epoch 10: mean 28.927536010742188, std 14.831731796264648\n",
      "Warning: trajectory cut off by epoch at 37 steps.\n",
      "epoch 11: mean 31.70400047302246, std 20.53329849243164\n",
      "Warning: trajectory cut off by epoch at 54 steps.\n",
      "epoch 12: mean 35.23214340209961, std 21.264062881469727\n",
      "Warning: trajectory cut off by epoch at 23 steps.\n",
      "epoch 13: mean 38.990196228027344, std 23.961774826049805\n",
      "Warning: trajectory cut off by epoch at 34 steps.\n",
      "epoch 14: mean 38.882354736328125, std 26.195829391479492\n",
      "Warning: trajectory cut off by epoch at 10 steps.\n",
      "epoch 15: mean 36.60550308227539, std 23.87775421142578\n",
      "Warning: trajectory cut off by epoch at 5 steps.\n",
      "epoch 16: mean 36.65137481689453, std 22.335792541503906\n",
      "Warning: trajectory cut off by epoch at 20 steps.\n",
      "epoch 17: mean 38.269229888916016, std 22.711498260498047\n",
      "Warning: trajectory cut off by epoch at 29 steps.\n",
      "epoch 18: mean 40.93814468383789, std 29.061548233032227\n",
      "Warning: trajectory cut off by epoch at 23 steps.\n",
      "epoch 19: mean 41.42708206176758, std 25.46351432800293\n",
      "Warning: trajectory cut off by epoch at 2 steps.\n",
      "epoch 20: mean 47.03529357910156, std 32.12638473510742\n",
      "Warning: trajectory cut off by epoch at 1 steps.\n",
      "epoch 21: mean 41.65625, std 28.607555389404297\n",
      "Warning: trajectory cut off by epoch at 2 steps.\n",
      "epoch 22: mean 42.08420944213867, std 24.576265335083008\n",
      "epoch 23: mean 47.619049072265625, std 28.839420318603516\n",
      "Warning: trajectory cut off by epoch at 48 steps.\n",
      "epoch 24: mean 58.98507308959961, std 35.37749099731445\n",
      "Warning: trajectory cut off by epoch at 6 steps.\n",
      "epoch 25: mean 54.71232986450195, std 40.277626037597656\n",
      "Warning: trajectory cut off by epoch at 42 steps.\n",
      "epoch 26: mean 53.486488342285156, std 34.643062591552734\n",
      "Warning: trajectory cut off by epoch at 20 steps.\n",
      "epoch 27: mean 55.27777862548828, std 40.630184173583984\n",
      "Warning: trajectory cut off by epoch at 172 steps.\n",
      "epoch 28: mean 54.68571472167969, std 33.43460464477539\n",
      "Warning: trajectory cut off by epoch at 44 steps.\n",
      "epoch 29: mean 58.17647171020508, std 33.867366790771484\n",
      "Warning: trajectory cut off by epoch at 75 steps.\n",
      "epoch 30: mean 60.38461685180664, std 39.619998931884766\n",
      "Warning: trajectory cut off by epoch at 127 steps.\n",
      "epoch 31: mean 56.95588302612305, std 33.66724395751953\n",
      "Warning: trajectory cut off by epoch at 32 steps.\n",
      "epoch 32: mean 62.984127044677734, std 39.1778564453125\n",
      "Warning: trajectory cut off by epoch at 10 steps.\n",
      "epoch 33: mean 61.38461685180664, std 40.75053405761719\n",
      "Warning: trajectory cut off by epoch at 31 steps.\n",
      "epoch 34: mean 65.0655746459961, std 37.75931930541992\n",
      "Warning: trajectory cut off by epoch at 52 steps.\n",
      "epoch 35: mean 58.92537307739258, std 36.41482162475586\n",
      "Warning: trajectory cut off by epoch at 60 steps.\n",
      "epoch 36: mean 66.7796630859375, std 38.319828033447266\n",
      "Warning: trajectory cut off by epoch at 27 steps.\n",
      "epoch 37: mean 63.06349182128906, std 35.557186126708984\n",
      "Warning: trajectory cut off by epoch at 68 steps.\n",
      "epoch 38: mean 74.18868255615234, std 43.32286071777344\n",
      "Warning: trajectory cut off by epoch at 3 steps.\n",
      "epoch 39: mean 70.12281036376953, std 37.969547271728516\n",
      "Warning: trajectory cut off by epoch at 110 steps.\n",
      "epoch 40: mean 65.93220520019531, std 38.05030822753906\n",
      "Warning: trajectory cut off by epoch at 3 steps.\n",
      "epoch 41: mean 85.04255676269531, std 42.57856369018555\n",
      "epoch 42: mean 74.0740737915039, std 44.00330352783203\n",
      "Warning: trajectory cut off by epoch at 50 steps.\n",
      "epoch 43: mean 82.29166412353516, std 45.881168365478516\n",
      "Warning: trajectory cut off by epoch at 32 steps.\n",
      "epoch 44: mean 74.86792755126953, std 40.78523635864258\n",
      "Warning: trajectory cut off by epoch at 28 steps.\n",
      "epoch 45: mean 77.88235473632812, std 50.52494812011719\n",
      "Warning: trajectory cut off by epoch at 105 steps.\n",
      "epoch 46: mean 88.5227279663086, std 43.87662887573242\n",
      "Warning: trajectory cut off by epoch at 38 steps.\n",
      "epoch 47: mean 88.04444122314453, std 48.69083786010742\n",
      "Warning: trajectory cut off by epoch at 24 steps.\n",
      "epoch 48: mean 79.5199966430664, std 46.228668212890625\n",
      "Warning: trajectory cut off by epoch at 43 steps.\n",
      "epoch 49: mean 94.21428680419922, std 47.35707092285156\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8k9e9+PHP8d42HhjP2AazN4aQMLIgq2lKCW2TJi0ZDV23TdKZdNz03vbXmzS3I72dJGlC2gwyC80ggyxKEoIBG5tpMGBbNrZsLHkv6fz+0GNjg2TLQ7Isf9+vl1+SnvnVI/nr43POc47SWiOEEGLsCxjtAIQQQowMSehCCOEnJKELIYSfkIQuhBB+QhK6EEL4CUnoQgjhJyShCyGEn5CELoQQfkISuhBC+Ikgb54sMTFRZ2VlefOUQggx5u3Zs6dWa5000HZeTehZWVnk5+d785RCCDHmKaVOubOdVLkIIYSfkIQuhBB+QhK6EEL4CUnoQgjhJyShCyGEn5CELoQQfkISuhBC+AlJ6EII4UEl1Y385q2j1DS0efxcktCFEMKDdp+s5/fbS2jvsnv8XJLQhRDCg0rNTYQGBZAWF+7xc0lCF0IIDyqtbSY7MZKAAOXxc0lCF0IIDyo1NzE5Kcor55KELoQQHtLeZaPsTAs5SZFeOZ8kdCGE8JCyuhbsGknoQggx1h03NwNIlYsQQox1x81NAGQn+lAJXSl1l1KqWCl1QCl1t7EsXin1llKqxHic4NlQhRBibCk1NzMxOpTosGCvnG/AhK6Umg3cCSwB5gHXKaWmAPcC27XWucB247UQQghDaW2T1+rPwb0S+gxgl9a6RWvdBbwPrAU+A2wyttkErPFMiEIIMfZorSk1N3ut/hzcS+jFwAqlVIJSKgK4FsgAkrXWVcY2p4FkD8UohBBjTl1zB9bWTnK8mNAHnCRaa31IKfUg8CbQDBQAtnO20Uop7Wx/pdQGYANAZmbmsAMWQoixoNTo4eJrVS5orR/TWi/SWq8E6oGjQLVSKgXAeKxxse9GrXWe1jovKSlppOIWQgifVmr0cJniY1UuKKUmGo+ZOOrPnwa2AuuNTdYDWzwRoBBCjEXHzU2EBAWQ6oVBuboNWOVieFEplQB0At/UWluUUg8Azyml7gBOAZ/3VJBCCOFNWmu+/WwBLe1dzM+IY15GHPPS44iNcL/7Yam5meyESAK9MChXN7cSutZ6hZNldcAVIx6REEKMMpOllX8VVhIfGcL2w2drk7MTI5mfEccXFmewNCeh32OU1jYzfVK0p0Ptw90SuhBCjBuF5VYAnrhtMVmJkRRVWCkot1BYbuHtQ9UcqLTy5j2XuNy/o8tO2ZkWPjUnxVshA5LQhRDiPIUVFkICA5g+KYaQoACWTUlk2ZREAP7y/nEeeP0wNY1tTIwOc7p/2ZlmbHbt1R4uIGO5CCHEeQrKLcxMdSTzcy03EvuHx+pc7n+8p8ui93q4gCR0IYToo8tmp6jCyvyMOKfrZ6bEEBcRzL+P1bo8xmj0QQdJ6EII0UdJTROtnTaXCT0gQHHx5AR2HqtFa6f3U1JqbiIpOpQYLw3K1RObV88mhBA+rrDcAsA8FwkdYNmURKqsbZyobXa6/ri5iRwvDZnbmyR0IYTopbDCQmx4MFkJES636a5H3+mi2qW0ttnr9ecgCV0I4cNMllY6bXavnnNfmYV5GXEo5fqGoMz4CNLiwp3Wo59p7sDS0slkL9efgyR0IYSPaunoYtWv32fThye9es6j1Y3MT4/tdzulFMunJPLR8Tps9r716N2zFHlz2NxuktCFED6p0tJKa6eNT06c8do5i00N2DXMz3Rdf95tWW4iDW1dFJusfZZ3D8rl7R4uIAldCOGjKupbAdhfYR1gy5HT3SA6N33ghH7xZMet/+dWu5SamwkJDCB9gus6eE+RhC6E8EmVljYATje0UdPQ5pVzFpRbSJ8QTmJU6IDbJkaFMn1S9HkNo8fNzWQlRnh1UK5uktCFED6p0tLa89xbpfSCcku/3RXPtXxKIvkn62ntODvnT6m5iZxE79efgyR0IYSPqrS0khgVQoCC/RUWj5/P3NiOydLKgkEk9GW5iXTY7OSfctTzd9ocg3JNnuj9+nOQhC6E8FEVllZyEqOYmhxNoRdK6N1/NAZTQl+SFU9woGKnMa5L2ZkWuuxaSuhCCNFbpaWV1Lgw5qTFUmSyurzNvredx2p5fOeJIZ2voNxCYIBidmr/XRZ7iwwNYkHGhJ569OM1o9fDBSShCyF8kM2uOW1tIzUunLkZcZxp7ujp9dKfh98u4RevHsLa0jnocxaUW5iWHE14SOCg9ls2JZHiSiv1zR2U1o7OKIvdJKELIXyOubGdLrsmNS6cecZNPgM1jDa2dbK3rB6bXfPeUadz1ruktaZwkA2i3ZbnJqA1fFRaR6m5icSoUGLDvTsoVzdJ6EIIn2MyerikxYUzbVI0wYGK/ab+G0Y/Ol5Hl10ToOCtg9WDOt+J2mYa2rqYn+F+dUu3uelxRIYEsvNYLaXm5lGrbgE3E7pS6h6l1AGlVLFS6hmlVJhSKlsptUspdUwptVkpFeLpYIUQ40NPQp8QTmhQIDNSYthf3n8JfUdJLREhgayZn8b7R8x0dLk/BkzhEBpEuwUHBrA0xzGc7nFz06iM4dJtwISulEoDvg3kaa1nA4HAjcCDwG+11lOAeuAOTwYqhBg/uvugp8Q6pnibmx5LscmK3e66YXRHiZmlOQlcMyeFxvauQQ0ZUFhuJSIkkNyJQ5vUedmURE7WtVDf0jkqY7h0c7fKJQgIV0oFARFAFXA58IKxfhOwZuTDE0KMR5WWVmLCgog2JoiYmxZHY3sXJ+qcjz9eVtfCyboWVuYmsnxKIqFBAbx9yP1ql4JyC3PSYod8d+fy3MSe5z5d5aK1NgH/C5ThSORWYA9g0Vp3GZtVAGnO9ldKbVBK5Sul8s1m88hELYTwa44ui+E9r+dmdDeMOq9H/6DEkVtWTE0iPCSQFbmJvH2o2q2uju1dNg5WNricocgduROjSIp2DBcwWn3Qwb0qlwnAZ4BsIBWIBK529wRa641a6zytdV5SUtKQAxVCjB8mSxtpvRL6lKQowoMDXfZ02VFiJi0uvGeWoFUzkqmob+VIdeOA5zpc1UiHzT6shN49nG5IUADpE8IH3sFD3KlyWQWc0FqbtdadwEvAMiDOqIIBSAdMHopRCDHOmOpbSOuVGIMCA5iVGuM0oXfZ7Hx4rI6VUxN7JqW4fPpEAN52o7fLcBpEe/v+VdN4/NbFBAWOXudBd85cBixVSkUox9W6AjgIvAusM7ZZD2zxTIhCiPGksa2ThrauPlUu4OgeeKDSStc5MxgVlFtobO9iRe7ZGoCJMWHMy4jj7UMD90cvKLeQFB3a0wA7VKlx4Sybkjjwhh7kTh36LhyNn3uBImOfjcAPge8opY4BCcBjHoxTCDFOVFkdQ+Wen9Bjaeu0U2LcXt/tg5JaAhQsm9w3ma6eMZGCcgs1jf0PvVtQbmH+AFPOjRVu/W+gtb5faz1daz1ba/0lrXW71rpUa71Eaz1Fa/05rXW7p4MVQvi/szcV9S0xz0133jC6o8TMvIw4YiP63p25amYyAO/0U0q3tnZSam4eVv25L5E7RYUQPsVkjNlybgk9KyGS6LCgPiMvWls6KSy39Klu6TYtOZr0CeH9dl986I3DAKNeVTJSJKELIXxKpaWVoADFxOi+JfSAAOUYebFXQt95vBa7hpW55ydkpRSrZiSzo6S2zwQU3V7ZX8k/Pi7jq5fkSAldCCE8odLSyqTYMKc3+cxNj+Pw6QbauxwJekeJmejQIJc9VFbNSKa9y37eNHEna5u598UiFl0wge9dOW3k38QokYQuhPAplZa286pbus1Lj6XTpjlU1YjWmg+O1nLxlASCXXQVXJIdT3RoUJ9ql7ZOG998ei+BAYrf37TA5b5jkf+8EyGEXzBZWvvcVNTbHKNhtKjCwonaZkyWVqf1591CggK4ZFoSbx+q6RkH5pevHeJAZQO//tw8l+cZq4IG3kQIIbyjy2bndEMbqXHO+4SnxYWTEBlCYYUVm5GgV/aT0AFWz0zmlf1VFFZYqLS08eRHp7hzRXZPLxh/IgldCOEzahrbsdk1aXERTtcrpZibHsv+Cgv1zR1kJUSQmeB8226XTp1IYIDi8Z0nefdwDQsy4/jB1dM9Ef6okyoXIYTP6B4211UJHWBOehzHapr48Hhdv9Ut3WIjglmcNYGthZUEBCj+z8/qzXvzz3clhBiTes9U5Mq89FjsGlo7baxw0l3RmatnTQLgoXVzSZ/Qf4l+LJMqFyHEiKqyttLc3sWUIUwW0Z3QU/pJ6N0No0EBiosmJ7h13JuXXsDy3MQhxTSWSAldCDGifvrPYm7480dYWjoGvW+lpZXY8GCiQl2XNSdGh5EWF87CzAk9E2AMJDgwwO+TOUhCF0KMIK01+8osWFs7+cM7xwa9f+U546C78ocvLuCXa+cMJUS/JgldCDFiKq1t1DV3EB8ZwqaPTlJW1zK4/c+ZqciVBZkTmDJx9GYG8lWS0IUQI6bIGAnxf9bOISgggAeNwa/c5bipaHjjko9nktCFECOmyGQlKEBxydQkNqzM4dX9Vew5Ve/Wvg1tnTQ6mdhCuE8SuhBixOyvsDI1OZqw4EA2rMwhKTqUX752yK3Jms/2QZeEPlSS0IUQI0JrTZHJ2jMRRWRoEN9dPZU9p+rZVnx6wP27E3raKE6yPNZJQhdCjIiK+lYsLZ09/cQBPpeXwbTkaB7YdpiOLns/e4PJ4pgqzt8GzPKmARO6UmqaUqqg10+DUupupVS8UuotpVSJ8TjBGwELIXzTfmPiiblpZ8cmDwxQ3HftdE7VtfCPj0/1u7+pvpXgQEVSVKhH4/Rn7kwSfURrPV9rPR9YBLQALwP3Atu11rnAduO1EGKc2m+yEBIYwNRJfbsTXjI1iRW5ifz+nRKsLZ0u9++e2CLAycQWwj2DrXK5AjiutT4FfAbYZCzfBKwZycCEEGNLUYWV6SnRhAYF9lmulOK+a2Zgbe3kj++5vtmo0tJKaqxUtwzHYBP6jcAzxvNkrXWV8fw04H+DCwsh3GK3OxpE56TFOl0/MzWGdQvTeWLnScrPOL/ZqNLSKg2iw+R2QldKhQDXA8+fu047+iQ57ZeklNqglMpXSuWbzeYhByqE8F2nzrTQ2NblMqED3LN6KkrBb986et667oktpEF0eAZTQr8G2Ku17p6cr1oplQJgPNY420lrvVFrnae1zktKGnjsYiHE2FNkcjSI9u7hcq7UuHBuXZbFywUmDlU19Fl3uqENu5Y+6MM1mIR+E2erWwC2AuuN5+uBLSMVlBBibCmqsBASFMDU5P5HNPzGJVOIDg3iV9v6DglQaXRZlIQ+PG4ldKVUJLAaeKnX4geA1UqpEmCV8VoIMQ7tr7AyMyVmwJmAYiOC+eZlU3j3iJmPjtf1LO+5qUjGcRkWtxK61rpZa52gtbb2Wlantb5Ca52rtV6ltT7juTCFEL7KbtcU97pDdCDrL84iJTaMB7Yd7hkSwCS3/Y8IuVNUCDEspbXNNHfY+m0Q7S0sOJB7Vk+lsNzCGwccQwKYLK1MiAgmIkQmURsOSehCiGEpMjmGzJ2bHjfAlmfdsDCd3IlR/GrbEbpsdrfHQRf9k4QuhBiW/RVWwoMDmZwU6fY+gQGKH1w9ndLaZp7Lr5CEPkIkoQshXGps6+TK377f72iJRRVWZqbGEDRAg+i5Vs2YSN4FE/jd20epqG+VPugjQBK6EMKlHSW1HK1u4if/LKah7fxxWGx2zYHKBrfrz3tTSnHvNdOpaWynpcMmCX0ESEIXQrj03pEawoMDqWtu5zdvnn+H53FzE62dNrd7uJwrLyue1TMdo4ZIlcvwSZOyEMIprTXvHTFz+YyJxEeE8ORHJ1m3KJ3ZvUrjPUPmDjGhA9x3zXTqmtpZeIH7jarCOSmhCzGOdHTZe/p8D+RgVQM1je1cOjWJ7105jfjIEH66pRi7/eywTUUVFiJDAslOjOrnSP3LSYripW8sI0VGWhw2SehCjCP3vrifK3/zPtZW1+OSd3vviGMwvUumJREbEcx918xgX5mF5/LLe7bZb7IyKy2WQBnD3CdIQhdinPjwWC0v7TPR3GHj9aKqAbd/70gNs9NimBjtuB1/7cI0lmTF88C2w5xp7qDTZudgZQNzh9AgKjxDEroQ40B7l42fbCkmMz6CnMRIXtpr6nd7a0sne07Vc9m0iT3LlFL8fM1sGtu6+NW2w5RUN9HeZe93hEXhXdIoKsQ48OiOE5Sam3n8tsUcrGzgoTeOUFbXQmZChNPtdxwzY9dw6bS+Q15PmxTN7cuyeGTHiZ5lQ+myKDxDSuhC+LnyMy38fnsJ18yexGXTJrJmQRpKwUv7Klzu8+5hM3ERwczPOH/u97tWTSU5JpRnd5cTHRpEVoL7d4gKz5KELsQYtv1QNcUmq8v1Wmvu33qAwADFf356JgBpceFclJPAS3tNPaMd9ma3a94/amZFbpLTxs6o0CD+87pZAMxOi5VJnX2IJHQhxqjqhjbufDKfNX/cyR/fPYbNfn5yfuNANe8cruGeVVP7dAtcuzCdsjMt7DlVf94+ByobqG1q57JprmcYu3bOJO5Yns0tSy8YmTcjRoQkdCHGqJf3mbBrWJGbyENvHOGmRz6mov7sBMzN7V38178OMH1SNLcuy+qz79WzJxEeHMiLThpH3zvimE1y5VTXCV0pxU+vm8mn5qaMzJsRI0ISuhBjkNaaF/ZUkHfBBP5262J+8/l5HKxs4JqHd7ClwJGkH95eQpW1jV+smX3eTEJRoUFcPXsSr+yvpK3T1mfdu0dqmJceS2JUqNfejxgZktCFGIP2V1g5VtPEDYvSUUqxdmE6r9+1gqnJ0dz1bAEbnsznsX+f4At5GeRlxTs9xtqFaTS2dbH90Nn53eubOygot3BJr+6KYuyQhC7EGPTCngpCgwL6VHlkxEewecNS7lk1le2Ha4gOC+KH10x3eYyLJycyKSaMl/ae7e3yQYmju2J/9efCd7nVD10pFQc8CswGNHA7cATYDGQBJ4HPa63Pb2ERQoyotk4bWwsruXr2JGLCgvusCwoM4K5VuVw1OxmFIj4yxOVxAgMUaxak8ciOUmqb2kmMCuW9I2YmRAQPavYh4TvcLaE/DGzTWk8H5gGHgHuB7VrrXGC78VoIMURtnTb2ltU77UrY2/ZDNVhbO1m3KN3lNtMnxTBtUvSA51y7MA2bXbO1oLKnu+IlU513VxS+b8CErpSKBVYCjwForTu01hbgM8AmY7NNwBpPBSmEv2vp6OK2x3ez9k8fsrWwst9tX9hTTkpsGBdPThz2eacmRzMnLZaX9lWw32TlTHMHl0r9+ZjlTgk9GzADjyul9imlHlVKRQLJWuvuEX5OA8nOdlZKbVBK5Sul8s1m88hELYQfaWrv4ta/7WbXiToy4sP52dYD1Da1O922pqGND0pq+eyCtBErRa9dmEaxqYGNHxxHqf67Kwrf5k5CDwIWAn/WWi8AmjmnekU7/kd0+n+i1nqj1jpPa52XlCRfFCF6a2zrZP3fPmFPWT0P37iAx9Yvprndxv1bDzjd/p8FJmx2zQ39VLcM1qfnpRIUoHit6DTz0uP6rXcXvs2dhF4BVGitdxmvX8CR4KuVUikAxmONi/2F8DnHahrZUTK6/zFaWzu55bFPKCy38IebFvDpealMTY7m21dM4dX9VWwr7jvEbXff84WZcUxOGvqEEudKjArtGYTrMqluGdMGTOha69NAuVJqmrHoCuAgsBVYbyxbD2zxSIRCeMADrx/hjify+9xZ6U2Wlg5ufvRjDlZa+fMti7hmztnuh1+9ZDKzUmP4yT8PUN/c0bO8yGTlaHUT6xZljHg8Ny7OJEDBlbOc1pyKMcLdXi7fAp5SSu0H5gO/BB4AViulSoBVxmshxoQik4UOm53fvV3i9XOfae7gpkd2cbS6iY1fyuuZJLlbcGAAD62bh6Wlg/9+5WDPcmd9z0fKqpnJ5P9kNTNSYkb82MJ73EroWusCox58rtZ6jda6Xmtdp7W+Qmudq7VepbU+4+lghRgJNY1tVDe0kxQdykt7KyipbvTaubXW3PXsPkrNTTz65Twum+68imNmagzfuGwKL+8zsf1QNe1djr7nV86aRGx4sNN9hkvqzsc+uVNUjDvdw83+/DOziQgJ4tdvHvXauV/ca2JHSS0/+dSMAXuT/MdlU5iWHM2PXi7in/tMWFr673suhCR0Me4UmxpQCpbnJvKVFdlsO3CawnKLx89rbmzn568cZHHWBG6+cOBhZ0OCAnjoc3MxN7bz45eLSY4JZfmU4fc9F/5LEroYd4pMVrITI4kKDeIrK3KIjwzhoTeOePy8P9t6gNZOGw/cMNftSSHmpsexYeVkuuyatQvT5Q5O0S9J6GLcKTZZe+bBjAoN4huXTubfx2rZeazWY+d848BpXi2q4q4rcgfd5fDuVbncvSqX25dleyg64S8koYtxpbapnSprW5+JjW9ZegGpsWH86o0jA46jMhTW1k5++s9iZqTEsGFlzqD3DwsO5O5VU0mKlvHJRf8koYtxpchoEJ3dK6F3J8zCcgtvHKge8XP+z2uHqG1q51c3zD1vogkhRpJ8u8S4csBI6LNS+/a3XrswjclJkfz6zSNO5+bsz4naZiotrU7XfXislmd3l3PnyhzmpMc63UaIkeLWeOhC+IvuBtFoJ+OIf/fKaXzjqb28vM/kVvdAu13z+3dKem5OykmM5OIpCSybnMhFkxMIDQrk3peKyEqI4J5VUz3yfoToTRK6GFeKTQ0svGCC03XXzJ7EnLRYfvPmEaYlR/dbom5o6+Q7mwt4+1ANn12QxqzUGHYeq+WlvSb+8XEZSsGkmDCqrG08c+dSwoIDPfWWhOghCV2MG2eaOzBZWll/sfM+4Eopfnb9LO58Mp9P/+HfXD8vle9fNY2M+Ig+25VUN/LVv++h7EwLP/v0TNZfnIVSiq+syKHTZqew3MLOY3V8eLyWdYvSuWhygjfenhCS0MX44axB9FyLLpjAe9+/lL++f5zH/n2C14uruGXpBXzr8lziI0N4vaiK7z1fSHhIIE/fuZQl2X0nYA4ODCAvK568rHjuWpXr0fcjxLkkoYtxo7inQbT/xsmYsGC+f9V0vrQ0i9+9fZRNH57khfwKVkxN5LWi08zPiOMvtyxiUmyYN8IWwm3Sy0WMG8UmKxckRLg9uNWk2DAeuGEub9y9kgtzEnit6DQ3Lclg81eXSjIXPklK6GLcKDJZmZcx+Nnsc5OjeXR9HmeaO2REQuHTpIQuxoX65g4q6lv73CE6WJLMha+ThC7GheJKR/35cBK6EL5OEroYF4pNDcD5d4gK4U8koYtxodhkJSM+nLgIqTYR/sutRlGl1EmgEbABXVrrPKVUPLAZyAJOAp/XWtd7Jkwhhqeo15C5QvirwZTQL9Naz9da5xmv7wW2a61zge3GayF8jrWlk7IzLf3eUCSEPxhOlctngE3G803AmuGHI8TI624QnT3ADUVCjHXuJnQNvKmU2qOU2mAsS9ZaVxnPTwPJIx6dECOg+w5RqXIR/s7dG4uWa61NSqmJwFtKqcO9V2qttVLK6SDSxh+ADQCZmZnDClaIoSgyWUmLC2eC9CMXfs6tErrW2mQ81gAvA0uAaqVUCoDxWONi341a6zytdV5SUtLIRC3EIBRLg6gYJwZM6EqpSKVUdPdz4EqgGNgKrDc2Ww9s8VSQQgxVQ1snJ+tamJ0m/c+F/3OnyiUZeFkp1b3901rrbUqp3cBzSqk7gFPA5z0XphBDc8C4oUh6uIjxYMCErrUuBeY5WV4HXOGJoIQYKdIgKsYTuVNU+LUik5XU2DASokJHOxQhPE4SuvBbNrsm/+SZfucGFcKfSEIXPudkbTNP7DyB1k57wrrtgxIzldY2rp+XNkKRCeHbZIIL4XMe3HaY14tPMyc9jkUXTBjycZ76+BSJUaGsnin3vInxQUrowqfUNLbx1sFqAJ786OSQj2OytPLO4Rq+sDidkCD5movxQb7pwqc8n19Bl11z2bQkXiuqwtzYPqTjbP6kDA3ctETuThbjhyR04TPsds0zn5RxUU4CP7luJp02zbOflA36OJ02O8/uLueyaRNJnxDhgUiF8E2S0IXP+KDETEV9K1+8MJPJSVGsyE3k6U/K6LLZB3Wctw9WU9PYzs0XSulcjC+S0IXPeHpXGQmRIVw1axIAX1p6AVXWNt4+VD2o4zy1q4y0uHAunTbRE2EK4bMkoQufUN3QxvbDNazLO9uIecWMZNLiwtn04Sm3j3Oitpl/H6vlpiUZBAYoT4UrhE+ShC58wnO7y7HZNTctPltNEhiguHlpJh+V1lFS3ejWcZ7edYqgAMXnF2d4KlQhfJYkdDHqbHbNs7vLWT4lkazEyD7rvpCXQUhgAH//eOBSelunjef3VHDVrElMjA7zVLhC+CxJ6GLUfXDUjMnS6rSLYUJUKNfNS+HFPRU0tnX2e5zXi6uwtHRKY6gYtyShi1H31K4yEqNCXN7R+eWLsmjusPHyPlO/x/nHx2XkJEZy0eQET4QphM+ThC5GVZW1lXcOV/O5vAyXd3TOz4hjbnosT350yuX4LoeqGthzqp4vXpiJMXa/EOOOJHQxqjbvLseu6dMY6syXL8riWE0THx2vc7r+6V1lhAQFsG5RuifCFGJMkMG5xKjpstnZvLucFbmJZCb0f0fndXNT+H+vHuTJj06xJDueE7XNHKhs4GBVAwcqrew+Uc9181KIi5CJoMX4JQldjJr3jpipsrZx/6dnDrhtWHAgn1+cwcYPSpl1/xu0dznuHg0JCmD6pGhuWJTOPatyPR2yED5NErrwCrtdc8zcxL6yegrKLewrs3C0upHkmFCumOHe8LZ3LMum/EwLqbHhzEyNYVZqLDlJkQQHSs2hEDCIhK6UCgTyAZPW+jqlVDbwLJAA7AG+pLXu8EyYYqzqtNm576UithWfpqm9C4CYsCDmZ07gylmTuH5eqtsJeWJMGH+6eZEnwxViTBtMCf2TYWiEAAARIElEQVQu4BAQY7x+EPit1vpZpdRfgDuAP49wfGIM01pz/9YDvLCngnWL0lmak8CCzDiyEyIJkNvyhRhxbhWNlFLpwKeAR43XCrgceMHYZBOwxhMBirHrbztP8vSuMr52yWT+93PzWLconclJUZLMhfAQdysffwf8AOgexzQBsGitu4zXFYBM3Ch6bD9UzS9ePchVs5L5wVXTRjscIcaFARO6Uuo6oEZrvWcoJ1BKbVBK5Sul8s1m81AOIcaYQ1UNfPuZfcxKjeG3X5gvJXIhvMSdOvRlwPVKqWuBMBx16A8DcUqpIKOUng44vS9ba70R2AiQl5c3vGncxZDtKq2jtLaZiJBAIkOCiAgNJCo0iIiQIDLiwwkNChyR89Q0tnHHE7uJDgvmsfWLiQiRjlRCeMuAv21a6/uA+wCUUpcC39Na36yUeh5Yh6Ony3pgiwfjFMOwv8LCjY98jIu75pmcFMkzdy5lYszwRihs67Rx55N7qG/p5PmvXUTyMI8nhBic4RSffgg8q5T6BbAPeGxkQhIjyW7X/HTLARKjQnnuqxdh15rm9i6a2220dHRR3dDOL149yE2PfMyzGy4iKTp0SOfptNn57nOF7K+w8JdbFjE7LXaE34kQYiCDSuha6/eA94znpcCSkQ9JjKTn8sspLLfw2y/MI/ucsca7TU6K5NbHd/PFRz7m6TuXDjqpn6pr5tvPFlBYbuFH107vmUJOCOFdcoudH7O0dPDgtsMsyYpnzXzXnZAuzEng8dsWU1Hfys2PfkxtU7tbx9da8+KeCq59eAel5ib+8MUFbFg5eaTCF0IMkiR0P/bQG0doaOviv9fMGnBI2aU5CTx2ax5lZ1q45dFd1A2Q1BvaOrnr2QK++3whs1Jj2Xb3Sq6bmzqS4QshBkkSup/aX2Hh6U/KWH9RFtMnxQy8A3Dx5EQeW7+YE7XN3PzoLs40Ox/JIf/kGa753Q5eLariu6un8syGpaTFhY9k+EKIIZA+ZX6ouyE0ITKUu1cPbgTCZVMcSf2OTbu57H/fIyIkkE6bptNmp8tmp9Ou6eiykxkfwfNfu4iFmRM89C6EEIMlCd0P9W4IjQkLHvT+y3MTefL2JTyXX0FgAAQFBhAcoAgKDCAoUBEXHsItSzOJHsKxhRCeIwndz7jbEDqQC3MSuDBH5uYUYiyROnQ/M5iGUCGEf5GE7kcKygffECqE8B+S0P1Ep83OvS/uJzk6jHsG2RAqhPAPUofuJzZ+UMrh04088uU8aawUYpySErofKDU38fD2Ej41J4XVM92bn1MI4X8koY9xdrvmvpeKCAsK4P7rZ452OEKIUSQJfZTZ7ZonPzrJ2werh7T/5vxydp04w08+NZOJ0TJcrRDjmdShj6Km9i6+s7mANw9WExMWxI4fXE5shPv139UNbfzytUNclJPA5/LSPRipEGIskBL6KDlZ28zaP+1k++Ea7lieTUNbFxt3HB/UMe7fcoCOLju/XDtH+pwLIaSEPho+OGrmP57eS0CA4snbl7BsSiLVDW08vvMkty3LJjFq4PHItxWfZtuB0/zw6ukuxzkXQowvUkL3Iq01Gz84zq2Pf0JqXDhbv7mcZVMSAbhn9VTaOm386d2BS+kNbZ3855ZiZqbE8JUV2Z4OWwgxRkhC9xKbXfPd5wr55WuHuXr2JF78+sVkJkT0rJ+cFMW6Ren84+NTVFpaXR7Hbtd877lC6po7eOCGOQQHykcohHAYMBsopcKUUp8opQqVUgeUUv9lLM9WSu1SSh1TSm1WSoV4Ptyx6+evHOSlfSbuXpXLH7+4kMjQ82u7vn1FLhrN/71T4vI4D28v4c2D1fz42hnMTY/zZMhCiDHGneJdO3C51noeMB+4Wim1FHgQ+K3WegpQD9zhuTDHtsd3nuCJD09yx/Js7l411WUDZvqECL64JJPn8is4Wdt83vptxVU8vL2EdYvSuW1ZloejFkKMNQMmdO3QZLwMNn40cDnwgrF8E7DGIxGOcdsPVfPzVw6yemYyP7p2xoDbf/PyKQQHKn739tE+yw+fbuA7zxUyPyOOX6yZLb1ahBDncasCVikVqJQqAGqAt4DjgEVr3WVsUgEMffBtP1VssvKtZ/YxKzWWh2+cT2DAwEl4YnQYt16czZbCSo6cbgSgvrmDO5/MJyo0iL9+aRFhwYGeDl0IMQa5ldC11jat9XwgHVgCTHf3BEqpDUqpfKVUvtlsHmKYY0+VtZU7Nu0mLjyYx9bnERHifg/Rr12SQ1RIEL9+8whdNjvffHov1dZ2/vqlRSTHyN2gQgjnBtVFQmttAd4FLgLilFLdWSodMLnYZ6PWOk9rnZeUlDSsYMeKpvYu7ngin+Z2G4/dupiJg0zCcREhfGVFDm8erOarf9/Dh8fr+OXaOSyQ+TuFEP1wp5dLklIqzngeDqwGDuFI7OuMzdYDWzwV5Fhibe3k28/s40h1I3+8eSEzUoY20cTty7OYEBHM9sM13L4sm3WL5NZ+IUT/3KkHSAE2KaUCcfwBeE5r/YpS6iDwrFLqF8A+4DEPxunTtNbsr7Dy1K5TbC2spK3Tzi/WzOaSqUP/jyQ6LJj/WTuHD4/X8aNr3a7hEkKMY0pr7bWT5eXl6fz8fK+dz9Oa27vYWljJU7tOUWxqICIkkM/MT+PmCzOZnRY72uEJIfyEUmqP1jpvoO1kLBdDYbmFmsZ25mXE9jsMbU1DG+8fNfNBSS3vHq6hqb2L6ZOi+fma2ayZnyqzBQkhRo0kdGBLgYl7NhdgN/5ZSY0NY15GnOPHuBvzgxIz7x0xc6iqAYCk6FCunTOJLyzOZGFmnPQLF0KMunGf0P9VWMk9mwvIy4rnO6unUmyyUlhhpbDcwuvFp3u2CwpQ5GVN4IdXT+eSqUnMSImWJC6E8CnjOqG/ur+KuzcXkHdBPI/fupjI0CCW5iT0rD/T3EFhhQWbTXNhTrxUpwghfNq4TeivF1Xx7Wf3sSAjjsdvW+x0sKz4yBAumzZxFKITQojBG5djr24rPs23ntnH/Iw4nrh9idNkLoQQY43fZbKOLjt1ze2cae4AIEAp4weUUhyotPLd5wqZkx7LE7ctJkqSuRDCT4zpbHawsoFHd5RS3diGubEdc2M79S2dA+43LyOOTbcvkTpxIYRfGbMJvbqhjfWPf0J7p40pE6PIToxkSXY8SVFhJEWHEh8ZjFIKrTV2DXbjMVApLp2WJNUsQgi/MyazWnuXja//Yw/N7V28/I1lTJsUPdohCSHEqBuTCf2//nWQvWUW/nTzQknmQghhGHO9XJ75pIynd5Xx9Usnc+2clNEORwghfMaYSuh7y+q5f8sBVk5N4ntXThvtcIQQwqeMmYRe09DG1/6+h0mxYfzezenchBBiPBkTCb2jy843ntpLY1sXG7+8iLiIkNEOSQghfM6YaBT971cOkH+qnj98cQHTJw1tBiAhhPB3Pl9C11qTlRDJNy+bzHVzU0c7HCGE8Fk+X0JXSvGVFTmjHYYQQvg8ny+hCyGEcM+ACV0plaGUelcpdVApdUApdZexPF4p9ZZSqsR4nOD5cIUQQrjiTgm9C/iu1nomsBT4plJqJnAvsF1rnQtsN14LIYQYJQMmdK11ldZ6r/G8ETgEpAGfATYZm20C1ngqSCGEEAMbVB26UioLWADsApK11lXGqtNA8ohGJoQQYlDcTuhKqSjgReBurXVD73Vaaw1oF/ttUErlK6XyzWbzsIIVQgjhmlsJXSkVjCOZP6W1fslYXK2USjHWpwA1zvbVWm/UWudprfOSkpJGImYhhBBOuNPLRQGPAYe01r/ptWorsN54vh7YMvLhCSGEcJdy1Jb0s4FSy4EdQBFgNxb/CEc9+nNAJnAK+LzW+swAxzIb2/YnEagdMPLR4aux+WpcILENlcQ2NL4a23DjukBrPWAVx4AJ3duUUvla67zRjsMZX43NV+MCiW2oJLah8dXYvBWX3CkqhBB+QhK6EEL4CV9M6BtHO4B++GpsvhoXSGxDJbENja/G5pW4fK4OXQghxND4YgldCCHEUGitfeIHuBo4AhwD7vXgeTKAd4GDwAHgLmP5zwATUGD8XNtrn/uMuI4AVw0UM5CNo1vnMWAzEDKI+E7i6CJaAOQby+KBt4AS43GCsVwBvzfOsx9Y2Os4643tS4D1vZYvMo5/zNhXuRHTtF7XpQBoAO4erWsG/A3HjWzFvZZ5/Bq5OocbsT0EHDbO/zIQZyzPAlp7Xb+/DDWG/t7nALF5/DMEQo3Xx4z1WW7GtrlXXCeBAm9fN1znC5/4vp13HT2RNAf7AwQCx4EcIAQoBGZ66Fwp3RcZiAaOAjONL/b3nGw/04gn1PjCHjfidRkzjv75NxrP/wJ8fRDxnQQSz1n2q+5fHByjWj5oPL8WeN34Ei0FdvX6IpQajxOM591fuE+MbZWx7zVD+KxOAxeM1jUDVgIL6fvL7/Fr5OocbsR2JRBkPH+wV2xZvbc75ziDisHV+3QjNo9/hsA3MJIucCOw2Z3Yzln/a+A/vX3dcJ0vfOL7dt77H8wvs6d+gIuAN3q9vg+4z0vn3gKs7ueL3ScW4A0jXqcxGx9KLWd/gfts50Y8Jzk/oR8BUnp9wY4Yz/8K3HTudsBNwF97Lf+rsSwFONxreZ/t3IzvSmCn8XzUrhnn/FJ74xq5OsdAsZ2z7rM4htBwud1QYnD1Pt24bh7/DLv3NZ4HGdud959hP9dDAeVA7mhdt17ru/OFz3zfev/4Sh16Go4PrFuFscyjzhk9EuA/lFL7lVJ/6zVhh6vYXC1PACxa665zlrtLA28qpfYopTYYy1yNbDnY2NKM5+cuH4wbgWd6vfaFawbeuUYjMcLo7ThKYd2ylVL7lFLvK6VW9Ip5sDEM53fI059hzz7GequxvbtWANVa65Jey7x+3dwcbXZUv2++ktC9zsnokX8GJgPzgSoc/+KNhuVa64XANTgmE1nZe6V2/LnWoxGYUioEuB543ljkK9esD29co6GcQyn1YxwTxjxlLKoCMrXWC4DvAE8rpWI8GYMTPvkZnuMm+hYivH7dhjra7Ehx9xy+ktBNOBofuqUbyzzC2eiRWutqrbVNa20HHgGWDBCbq+V1QJxSKuic5W7RWpuMxxocDWhLcD2y5WBjMxnPz13urmuAvVrraiNGn7hmBm9cI7dGGHVGKXUrcB1ws/HLida6XWtdZzzfg6NueuoQYxjS75CXPsOefYz1scb2AzK2X4ujgbQ7Zq9et0GONjuq3zdfSei7gVylVLZRCrwRx2iOI87V6JHdF87wWaDYeL4VuFEpFaqUygZycTRiOI3Z+GV9F1hn7L8eN0eiVEpFKqWiu5/jqK8uxvXIlluBLyuHpYDV+BftDeBKpdQE41/oK3HUZ1YBDUqppcZ1+LK7sRn6lJR84Zr14o1rNKQRRpVSVwM/AK7XWrf0Wp6klAo0nufguE6lQ4zB1fscKDZvfIa9Y14HvNP9R80Nq3DUMfdUS3jzurnKF0M4nne+bwNVsnvrB0fr8FEcf21/7MHzLMfxr8t+enXVAv6Oo+vQfuNCpvTa58dGXEfo1SvEVcw4egB8gqMb0vNAqJux5eDoNVCIo4vUj43lCTjmbS0B3gbi9dnGoj8a5y8C8nod63bj/MeA23otz8PxS3sc+ANudFs09ovEUaqK7bVsVK4Zjj8qVUAnjjrHO7xxjVydw43YjuGoP+3TzQ64wficC4C9wKeHGkN/73OA2Dz+GQJhxutjxvocd2Izlj8BfO2cbb123XCdL3zi+3buj9wpKoQQfsJXqlyEEEIMkyR0IYTwE5LQhRDCT0hCF0IIPyEJXQgh/IQkdCGE8BOS0IUQwk9IQhdCCD/x/wEpCczLbHaaTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vpg(gym.make('CartPole-v0'), ac_kwargs=dict(hidden_sizes=[64] * 2), gamma=0.99, seed=0, steps_per_epoch=4000, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
